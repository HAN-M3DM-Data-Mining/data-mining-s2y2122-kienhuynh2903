---
title: "Assigment - Naive Bayes Sabotaged"
author:
  - Kien Huynh Trung - Author
  - Dang Nguyen - Reviewer
date: March 20, 2022
output:
   html_notebook:
    toc: true
    toc_depth: 2
---

```{r}
library(tidyverse)
library(tm)
library(caret)
library(wordcloud)
library(e1071)
library(dplyr)
library(SnowballC)
```
---
NB-fakenews.csv

## Business Understanding
Identify fake news using Naive Bayes model. 

## Data Understanding
```{r}
url <- "https://raw.githubusercontent.com/HAN-M3DM-Data-Mining/data-mining-s2y2122-kienhuynh2903/master/datasets/NB-fakenews.csv"
rawDF <- read.csv (url)
rawDF<- rawDF[-c(1:15000),]
head (rawDF)
str (rawDF)
rawDF$id <- NULL 
rawDF$title <- NULL
rawDF$author <- NULL
rawDF <- rawDF %>% relocate(label, .before = text)
rawDF <- mutate(rawDF, label = recode(label,"0"= "ham", "1"= "spam"))
class(rawDF$label)

spam <- rawDF %>% filter(label == "spam")
ham <- rawDF %>% filter(label == "ham")

wordcloud (spam$text, max.words = 20, scale = c(4, 0.8), colors= c("indianred1","indianred2","indianred3","indianred"))
wordcloud (ham$text, max.words = 20, scale = c(4, 0.8), colors= c("lightsteelblue1","lightsteelblue2","lightsteelblue3","lightsteelblue"))
gc()
```

## Data Preparation
```{r}
rawCorpus <- Corpus(VectorSource(rawDF$text))
inspect(rawCorpus[1:3])
cleanCorpus <- rawCorpus %>% tm_map(tolower) %>% tm_map(removeNumbers)
cleanCorpus <- cleanCorpus %>% tm_map(tolower) %>% tm_map(removeWords, stopwords()) %>% tm_map(removePunctuation)
cleanCorpus <- cleanCorpus %>% tm_map(stripWhitespace)
cleanCorpus <- cleanCorpus %>% tm_map(stemDocument)
cleanCorpus <- tm_map(cleanCorpus, removeWords, stopwords("english"))

tibble(Raw = rawCorpus$content[1:3], Clean = cleanCorpus$content[1:3])

cleanDTM <- cleanCorpus %>% DocumentTermMatrix
set.seed(1234)
trainIndex <- createDataPartition(rawDF$label, p = .25, 
                                  list = FALSE, 
                                  times = 1)
head(trainIndex)

trainDF <- rawDF[trainIndex, ]
testDF <- rawDF[-trainIndex, ]

trainCorpus <- cleanCorpus[trainIndex]
testCorpus <- cleanCorpus[-trainIndex]

trainDTM <- cleanDTM[trainIndex, ]
testDTM <- cleanDTM[-trainIndex, ]

freqWords <- trainDTM %>% findFreqTerms(5000)

trainDTM <-  DocumentTermMatrix(trainCorpus, list(dictionary = freqWords))
testDTM <-  DocumentTermMatrix(testCorpus, list(dictionary = freqWords))

convert_counts <- function(x) {
  x <- ifelse(x > 0, 1, 0) %>% factor(levels = c(0,1), labels = c("No", "Yes"))
}

nColsDTM <- dim(trainDTM)[2]
trainDTM <- apply(trainDTM, MARGIN = 2, convert_counts)
testDTM <- apply(testDTM, MARGIN = 2, convert_counts)

head(trainDTM[,1:10])

```
## Modeling
```{r}
nbayesModel <-  naiveBayes(trainDTM, trainDF$label, laplace = 1)
predVec <- predict(nbayesModel, testDTM)
confusionMatrix(predVec, testDF$label, positive = "spam", dnn = c("Prediction", "True"))

```
## Evaluation and Deployment
The model gives the result of 77.6 percent of accuracy level. I tried to remove unnecessary words but it seems not to be helpful. 

Hence, the reviewer may add suggestion to improve the model. 
         
